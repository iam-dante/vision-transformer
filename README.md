# Vision Transfomer
A vision transformer, or ViT, is a deep learning architecture designed for computer vision tasks. Unlike traditional convolutional neural networks (CNNs), which rely on convolutional layers to process image data, ViTs utilize self-attention mechanisms commonly found in transformer models. 

<image src="./images/info-readme-architecture.png" alt="" height="300" wight="700"/>

From the diagram is guided by four equation from the below table that shows how one image is passed through out the architecture during training and inference.

<image src="./images/info-equations.png" alt="" height="200" wight="700"/>

This repository focus on the base architecture of visiion transformer of 12 layers but configure in a way that the hyperparameters can be changed


<image src="./images/info-table.png" alt="" height="200" wight="700"/>

